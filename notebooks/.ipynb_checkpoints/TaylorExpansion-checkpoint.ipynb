{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Introduction\n",
    "\n",
    "## Philosophy of the course\n",
    "Numerous scientific problems can only be addressed through modeling and computer analysis. This stems from the fact that a lot of these problems are complex and the corresponding models cannot be solved using only pen-and-paper. \n",
    "\n",
    "Many models appearing in engineering or physical applications are mathematically described by partial differential equations (PDE) and the aim of this course is to provide a practical introduction to the relevant tools to solve them. By practical we mean that we will not develop the theory behind PDEs and also avoid complex mathematical derivations of the numerical methods we describe below. Although these are beautiful subjects, they are often characterized by a steep learning curve and our objective is to get our hands on solving real problems as quickly as possible. In some places we nevertheless provide some mathematical background about the techniques we describe because they cannot be properly understood otherwise. In each case, we try to keep things simple and written in such a way that the corresponding section may be skipped at first reading.\n",
    "\n",
    "## Outline\n",
    "To be written\n",
    "\n",
    "## Python and why python\n",
    "\n",
    "All the pieces of code written in this course are written in Python. However, we try to make the required prior knowledge of Python as little as possible and the reader is only expected to have a basic knowledge of any programming language and be familiar with concepts like variables, loops, conditional statements, functions etc.\n",
    "\n",
    "# Approximations and Taylor expansion\n",
    "\n",
    "In general, the resolution of numerical problems require some approximations.\n",
    "\n",
    "The first one is related to the fact that most real numbers need an infinite numbers of digits after the decimal point to be properly represented. To store these numbers in the memory of a computer one therefore needs to cut their representation at some point beyond the decimal point. The number of digits kept is called the precision of the representation. For example, in *single precision* and *double precision*, $\\pi$ is given by the following approximations:\n",
    "\n",
    "\\begin{align}\n",
    "\\pi &= 3.1415927 \\quad\\quad &\\text{(single precision)}\\\\\n",
    "\\pi &= 3.141592653589793 \\quad\\quad &\\text{(double precision)}\\\\\n",
    "\\end{align}\n",
    "\n",
    "In this course, we always use double precision for real numbers as this is the default precision used by Python. Such a precision is large enough for the kind of numerical problems we consider, but the reader should still be aware that rounding off errors can cause some difficulties as they can get amplified when certain operations are performed or when some iterative procedures are used. Two good references to get started on the subject are:\n",
    "\n",
    "- https://docs.python.org/3/tutorial/floatingpoint.html\n",
    "- https://floating-point-gui.de\n",
    "\n",
    "In the context of the numerical discretisation of ordinary or partial diffential equations, the more significant limitation in precision usually comes from the limited computer resources available to solve a problem or the time needed to get the solution. Indeed, from the physical point of view, both time and space are continuous variables...\n",
    "\n",
    "## Taylor's theorem\n",
    "\n",
    "In order to estimate the accuracy of discretized differential operators or time integration schemes, Taylor's theorem provides a valuable tool. Let $x$ be any point in the interval $[a\\ b]$ and $\\Delta x$ a small positive real number. Schematically we have:\n",
    "\n",
    "<img src=\"figures/taylor.png\">\n",
    "\n",
    "Any *well behaved* function in $[a\\ b]$ can then be approximated using the following expression (Taylor's expansion) $\\cite{Arfken}$:\n",
    "\n",
    "\\begin{align}\n",
    "f(x+\\Delta x)=f(x)+f'(x)\\Delta x+\\frac{f''(x)}{2!}\\Delta x^2+\\dots + \\frac{f^{(k)}(x)}{k!}\\Delta x^k + R_{k+1}\n",
    "\\label{eq:taylorExpansion}\n",
    "\\end{align}\n",
    "\n",
    "with,\n",
    "\n",
    "\\begin{align}\n",
    "R_{k+1} = \\frac{f^{k+1}(\\xi)}{(k+1)!}\\Delta x^{k+1}, \\quad\\quad x\\leq \\xi \\leq x+\\Delta x\n",
    "\\end{align}\n",
    "\n",
    "In the above formula, $f^{(k)}$ denotes the $k$-th derivative of $f$. Note that at this stage, no approximations have been made. Assuming that $\\vert f^{(k)}\\vert$ is bounded by a constant $C$ in $[a\\ b]$, we can then write:\n",
    "\n",
    "\\begin{align}\n",
    "\\vert R_{k+1}\\vert \\leq \\frac{C}{(k+1)!}\\Delta x^{k+1}\\label{eq:remainder}\n",
    "\\end{align}\n",
    "\n",
    "Equation $\\ref{eq:remainder}$ gives a bound on the error made by dropping terms beyond $\\frac{f^{(k)}(x)}{k!}\\Delta x^k$ in $\\ref{eq:taylorExpansion}$. One can then write $R_{k+1}$ using the so-called big O notation:\n",
    "\n",
    "\\begin{align}\n",
    "R_{k+1} = O(\\Delta x^{k+1})\n",
    "\\end{align}\n",
    "\n",
    "The above notation means that $\\vert R_{k+1}\\vert$ goes to $0$ at least as fast as $\\Delta x^{k+1}$ for $\\Delta x \\rightarrow 0$. We then say that the approximation,\n",
    "\n",
    "\\begin{align}\n",
    "f(x+\\Delta x)\\approx f(x)+f'(x)\\Delta x+\\frac{f''(x)}{2!}\\Delta x^2+\\dots + \\frac{f^{(k)}(x)}{k!}\\Delta x^k\n",
    "\\end{align}\n",
    "\n",
    "is of order $k+1$. Importantly, this implies that the remainder is at least reduced by a factor of $2^{k+1}$ if $\\Delta x$ is divided by $2$. This is a very important concept that will be discussed numerous times in this course.\n",
    "\n",
    "## Expansion of $e^x$\n",
    "\n",
    "To make things more concrete and to write our first python code of the course, let us consider the Taylor expansion of the exponential function $e^x$ around $x=0$. According to \\ref{eq:taylorExpansion}, one has:\n",
    "\n",
    "\\begin{align}\n",
    "e^{\\Delta x} = 1 + \\Delta x + \\frac{(\\Delta x)^2}{2} + R_3,\\quad\\quad R_3=e^{\\xi} \\frac{(\\Delta x)^3}{3!}, \\quad\\quad 0\\leq \\xi \\leq \\Delta x.\n",
    "\\end{align}\n",
    "\n",
    "As $e^x$ is monotonously inscreasing, we certainly can bound $e^{\\xi}$ by $e$ when $\\Delta x \\rightarrow 0$. Therefore, $\\vert R_3 \\vert \\leq e \\frac{(\\Delta x)^3}{3!} = O(\\Delta x)^3$. Let's check using python that this is indeed the case.\n",
    "\n",
    "We first import two packages that... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('./mainstyle.use')\n",
    "\n",
    "delta_list = [2**(-k) for k in range(1, 10)]\n",
    "\n",
    "delta = np.asarray(delta_list)\n",
    "print(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R3 = np.exp(delta) - (1 + delta + delta**2 / 2)\n",
    "slope = delta**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.loglog(delta, R3, '*', label=r'$R_3$')\n",
    "ax.loglog(delta, slope, color='green', label=r'$\\Delta^{-3}$')\n",
    "ax.set_xlabel(r'$\\Delta x$')\n",
    "ax.set_ylabel(r'$R_3$')\n",
    "ax.set_title(r'Accuracy')\n",
    "ax.legend()\n",
    "fig.savefig('sample.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "(<a id=\"cit-Arfken\" href=\"#call-Arfken\">?</a>) !! _This reference was not found in biblio.bib _ !!\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md",
   "text_representation": {
    "extension": ".md",
    "format_name": "markdown",
    "format_version": "1.2",
    "jupytext_version": "1.5.2"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
